[scripts]
# Install dependencies, configuration, and function code to each build folder
# Add "--deps" flag to re-install dependencies: pipenv run build --deps
# Note: may need to run as root if not running with --deps
# NOTE!!! For some reason the /lib folder is not being copied into
#  the identify_function/build/ folder... Check this! Do it manually if you need to.
#  Haven't found a fix yet
build = "bash ./build.sh "
# Build the VRT used by API functions
# Run with argument 'dev' or 'prod'
build_vrt = "python ./scripts/build_vrt/build_vrt.py -stage "
# Generate micro-datasets used by unit tests and build the accompanying VRT
test_prep = "bash ./scripts/make_test_data/make_test_data.py && ./scripts/build_vrt/build_vrt.py -stage test" 
#Run tests
tests = "docker run --rm -v ${PWD}:/var/task -it lambci/lambda:build-python3.6 /bin/bash -c './run-tests.sh'"
# Package and deploy changes to API
# Requires one argument: 'dev' or 'prod'
deploy = "bash ./deploy.sh"
# Display CloudFormation stack outputs (see template.yaml Outputs section)
outputs = "aws cloudformation describe-stacks --stack-name nfwf-tool-api-natureserve --query 'Stacks[].Outputs'"

# Make a new hubs shapefile with appended stats
prep_hubs = "python ./scripts/prep_hubs/prep_hubs.py "

cp_dataset = "bash -c \"aws s3 cp $0 s3://${DATA_BUCKET} \" "

[[source]]
url = "https://pypi.python.org/simple"
verify_ssl = true
name = "pypi"

[packages]
rasterio = { version = "==1.0", extras = ["s3"] }
pyproj = "*"
pyyaml = "*"

[dev-packages]
#click = "*"
#pytest = "*"
fiona = "==1.8.4"
shapely = "==1.6.4"
#requests = "*"

[requires]
python_version = "3.6"
